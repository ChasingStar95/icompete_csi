{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"colab_train.ipynb","provenance":[{"file_id":"1vAB1qfG6hppSmMBzUh6aHw3Z-94S_otJ","timestamp":1560679518284}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"NiL36gU5VdGj"},"source":["# auth\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ouRnMUQYB6zF","executionInfo":{"status":"ok","timestamp":1617258398966,"user_tz":-480,"elapsed":205399,"user":{"displayName":"tom ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfv8ARtHZvC3JpjKUHjRsPxO93qKRuYRVgJKF7DA=s64","userId":"16802545350315001940"}},"outputId":"d8cccb44-e9e9-4ec1-bdb7-464f577829b3"},"source":["\n","import json\n","import os\n","\n","\n","from google.colab import drive\n","drive.mount('/content/drive/')\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7zREzdFWBwjE"},"source":["# env"]},{"cell_type":"code","metadata":{"id":"QVM06cSX7zp0","executionInfo":{"status":"ok","timestamp":1617258398968,"user_tz":-480,"elapsed":205396,"user":{"displayName":"tom ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfv8ARtHZvC3JpjKUHjRsPxO93qKRuYRVgJKF7DA=s64","userId":"16802545350315001940"}}},"source":["import os, sys, logging\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","PROJECT = \"csi\"\n","WORKDIR = \"/content/icompete_csi\"\n","DATADIR = os.path.join(WORKDIR, 'data')\n","MODELNAME=\"CSI\"\n","NUM = int(1e16)\n","\n","sys.path.insert(0, WORKDIR)\n","os.environ['PYTHONPATH']=WORKDIR\n","!mkdir -p {DATADIR}\n","\n","os.chdir('/content')\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZIJGZxpH74KW","executionInfo":{"status":"ok","timestamp":1617258398969,"user_tz":-480,"elapsed":205393,"user":{"displayName":"tom ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfv8ARtHZvC3JpjKUHjRsPxO93qKRuYRVgJKF7DA=s64","userId":"16802545350315001940"}}},"source":[""],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T7B57t4dXRTS"},"source":["## code"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zp0LwYCj6_He","executionInfo":{"status":"ok","timestamp":1617258400210,"user_tz":-480,"elapsed":206632,"user":{"displayName":"tom ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfv8ARtHZvC3JpjKUHjRsPxO93qKRuYRVgJKF7DA=s64","userId":"16802545350315001940"}},"outputId":"0de0fe9e-4d03-40d1-daa9-c91e2d80a14f"},"source":["!cd /content && rm -rf icompete_csi && git clone https://github.com/world2vec/icompete_csi.git"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Cloning into 'icompete_csi'...\n","remote: Enumerating objects: 19, done.\u001b[K\n","remote: Counting objects: 100% (19/19), done.\u001b[K\n","remote: Compressing objects: 100% (15/15), done.\u001b[K\n","remote: Total 19 (delta 2), reused 16 (delta 2), pack-reused 0\u001b[K\n","Unpacking objects: 100% (19/19), done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"G_LDLArME1Ca"},"source":["# data"]},{"cell_type":"code","metadata":{"id":"8-edLrekE0Ba","executionInfo":{"status":"ok","timestamp":1617258431807,"user_tz":-480,"elapsed":238225,"user":{"displayName":"tom ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfv8ARtHZvC3JpjKUHjRsPxO93qKRuYRVgJKF7DA=s64","userId":"16802545350315001940"}}},"source":["!mkdir -p {DATADIR}/{PROJECT}\n","!cp  /content/drive/My\\ Drive/dl/{PROJECT}/data/H_4T4R.mat {DATADIR}/{PROJECT}"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DZ8NDDFkFBmz","executionInfo":{"status":"ok","timestamp":1617258431808,"user_tz":-480,"elapsed":238223,"user":{"displayName":"tom ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfv8ARtHZvC3JpjKUHjRsPxO93qKRuYRVgJKF7DA=s64","userId":"16802545350315001940"}},"outputId":"927a48a6-b5bb-49f9-d491-0e86e90abe15"},"source":["print(DATADIR)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/icompete_csi/data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MTh6bUnRDIgx","executionInfo":{"status":"ok","timestamp":1617258431809,"user_tz":-480,"elapsed":238220,"user":{"displayName":"tom ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfv8ARtHZvC3JpjKUHjRsPxO93qKRuYRVgJKF7DA=s64","userId":"16802545350315001940"}},"outputId":"18c36e71-cb38-4f1d-f21b-a56cf4b28620"},"source":["ls"],"execution_count":6,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34micompete_csi\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"csYGGNiWWJcP"},"source":["# requirements"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":594},"id":"VrEmncueWLjX","executionInfo":{"status":"ok","timestamp":1617258574420,"user_tz":-480,"elapsed":380826,"user":{"displayName":"tom ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfv8ARtHZvC3JpjKUHjRsPxO93qKRuYRVgJKF7DA=s64","userId":"16802545350315001940"}},"outputId":"1f632703-a7ea-4c78-96ad-9b6a49fd87c8"},"source":["\n","!pip install psutil==5.7.0 tqdm==4.45.0\n","!cd {WORKDIR}/{PROJECT} && ./setup.sh > /tmp/install.log\n","\n","\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Collecting psutil==5.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/b8/3512f0e93e0db23a71d82485ba256071ebef99b227351f0f5540f744af41/psutil-5.7.0.tar.gz (449kB)\n","\u001b[K     |████████████████████████████████| 450kB 16.3MB/s \n","\u001b[?25hCollecting tqdm==4.45.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/1c/6359be64e8301b84160f6f6f7936bbfaaa5e9a4eab6cbc681db07600b949/tqdm-4.45.0-py2.py3-none-any.whl (60kB)\n","\u001b[K     |████████████████████████████████| 61kB 8.9MB/s \n","\u001b[?25hBuilding wheels for collected packages: psutil\n","  Building wheel for psutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for psutil: filename=psutil-5.7.0-cp37-cp37m-linux_x86_64.whl size=276420 sha256=047e3ff74ba4d97e2e550c1fcbdb2c822a75bd37b3e85e18a0a168d1dafbad2b\n","  Stored in directory: /root/.cache/pip/wheels/d7/69/b4/3200b95828d1f0ddb3cb5699083717f4fdbd9b4223d0644c57\n","Successfully built psutil\n","Installing collected packages: psutil, tqdm\n","  Found existing installation: psutil 5.4.8\n","    Uninstalling psutil-5.4.8:\n","      Successfully uninstalled psutil-5.4.8\n","  Found existing installation: tqdm 4.41.1\n","    Uninstalling tqdm-4.41.1:\n","      Successfully uninstalled tqdm-4.41.1\n","Successfully installed psutil-5.7.0 tqdm-4.45.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["psutil"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["tcmalloc: large alloc 1147494400 bytes == 0x565079552000 @  0x7f9c3c8b9615 0x565040cf706c 0x565040dd6eba 0x565040cf9e8d 0x565040deb99d 0x565040d6dfe9 0x565040d68b0e 0x565040cfb77a 0x565040d6de50 0x565040d68b0e 0x565040cfb77a 0x565040d6a86a 0x565040dec7c6 0x565040d69ee2 0x565040dec7c6 0x565040d69ee2 0x565040dec7c6 0x565040d69ee2 0x565040dec7c6 0x565040e6e431 0x565040dcf049 0x565040d39c84 0x565040cfa8e9 0x565040d6eade 0x565040cfb69a 0x565040d69a45 0x565040d68e0d 0x565040cfb77a 0x565040d69a45 0x565040cfb69a 0x565040d69a45\n","tcmalloc: large alloc 1434370048 bytes == 0x5650bdba8000 @  0x7f9c3c8b9615 0x565040cf706c 0x565040dd6eba 0x565040cf9e8d 0x565040deb99d 0x565040d6dfe9 0x565040d68b0e 0x565040cfb77a 0x565040d6de50 0x565040d68b0e 0x565040cfb77a 0x565040d6a86a 0x565040dec7c6 0x565040d69ee2 0x565040dec7c6 0x565040d69ee2 0x565040dec7c6 0x565040d69ee2 0x565040dec7c6 0x565040e6e431 0x565040dcf049 0x565040d39c84 0x565040cfa8e9 0x565040d6eade 0x565040cfb69a 0x565040d69a45 0x565040d68e0d 0x565040cfb77a 0x565040d69a45 0x565040cfb69a 0x565040d69a45\n","tcmalloc: large alloc 1445945344 bytes == 0x565113394000 @  0x7f9c3c8b9615 0x565040cf706c 0x565040dd6eba 0x565040cf9e8d 0x565040deb99d 0x565040d6dfe9 0x565040d68b0e 0x565040cfb77a 0x565040d69c9e 0x565040d68b0e 0x565040cfb77a 0x565040d69c9e 0x565040d68b0e 0x565040cfb77a 0x565040d69c9e 0x565040d68b0e 0x565040cfb77a 0x565040d69c9e 0x565040d68b0e 0x565040cfb77a 0x565040d69c9e 0x565040cfb69a 0x565040d69c9e 0x565040d68b0e 0x565040cfb77a 0x565040d6a86a 0x565040d68b0e 0x565040cfb77a 0x565040d6a86a 0x565040d68b0e 0x565040cfbe11\n","\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1+cu110 which is incompatible.\u001b[0m\n","\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1+cu110 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.18.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RDPV41B2WCMH"},"source":["# tpu"]},{"cell_type":"code","metadata":{"id":"ME8B8T5PWD4C","executionInfo":{"status":"ok","timestamp":1617258575691,"user_tz":-480,"elapsed":382093,"user":{"displayName":"tom ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfv8ARtHZvC3JpjKUHjRsPxO93qKRuYRVgJKF7DA=s64","userId":"16802545350315001940"}}},"source":["import tensorflow as tf\n","\n","try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    print('Running on TPU ', tpu.master())\n","    USE_TPU = \"-use_tpu\"\n","except ValueError:\n","    USE_TPU = \"\"\n","if USE_TPU!=\"\":\n","    #mu.run_cmd(\"curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\")\n","    #mu.run_cmd(\"python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev\")\n","    !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n","    !python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev >/tmp/xla.log\n","    import torch_xla.core.xla_model as xm\n","    import torch_xla.distributed.parallel_loader as pl\n","    import torch_xla.distributed.xla_multiprocessing as xmp"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"goRMKFMoA07-"},"source":["# pretrain"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RRk1tbsdAy96","executionInfo":{"status":"ok","timestamp":1617259472632,"user_tz":-480,"elapsed":845648,"user":{"displayName":"tom ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfv8ARtHZvC3JpjKUHjRsPxO93qKRuYRVgJKF7DA=s64","userId":"16802545350315001940"}},"outputId":"e307596a-3b3b-4efe-e1fc-b788570bac81"},"source":["os.chdir(os.path.join(WORKDIR, PROJECT))\n","\n","BATCHSIZE = 512\n","KFID = 0\n","KN = 10\n","ENCDIM = 128\n","PQBIT=4\n","QBIT=4\n","WS=10000\n","LDS=100000\n","LR=8e-5\n","ELAYER=7\n","DLAYER=7\n","NHEAD=16\n","DEMODEL=544\n","DDMODEL=544\n","EFFD=2104\n","DFFD=2104\n","\n","\n","\n","\n","MINLOSS=0.085\n","MODELNAME=\"CSIPlus_p4geenc128ff2104q4e7d7h16d544_kf0b512abs1w1000lr1e4dp0ema999tqbest\"\n","\n","\n","!python train.py -m kf  -kfid {KFID} -kn {KN} -ms {MODELNAME} -num {NUM}  -save  -save_best $USE_TPU   -n_es_epoch 20 -n_lr_warmup_step {WS} -n_init_epoch 0 -bs {BATCHSIZE}  -abs 1 -ema 0.999   -xla_procs 1  -train_quantize  \\\n","-lr {LR}  -n_lr_decay_step {LDS} -lr_decay_rate 0.2  -dp 0 -enc_dim {ENCDIM} -n_q_bit {QBIT} -d_eff {EFFD} -d_dff {DFFD} -n_e_layer {ELAYER} -n_d_layer {DLAYER} -n_ehead {NHEAD}  -n_dhead {NHEAD} -d_emodel {DEMODEL}  -d_dmodel {DDMODEL} \\\n","-activation gelu  -save_half -use_fp16  -es 1e-5 -min_loss {MINLOSS}  -epochs 57 # -n_epoch_step 10 \n","!ls -ltrh ../data/{MODELNAME}_KF{KFID}/*"],"execution_count":11,"outputs":[{"output_type":"stream","text":["tcmalloc: large alloc 1843208192 bytes == 0x55a72449a000 @  0x7f0b8b2091e7 0x55a71ff58f48 0x55a71ff239c7 0x7f0ac890fb32 0x7f0ac8b2a973 0x7f0ac8b2f0bd 0x7f0ac8b328ee 0x7f0ac8b3a5c0 0x7f0ac8b2c5f5 0x55a71ff27050 0x55a72001899d 0x55a71ff9afe9 0x55a71ff95b0e 0x55a71ff2877a 0x55a71ff96c9e 0x55a71ff95b0e 0x55a71ff2877a 0x55a71ff96c9e 0x55a71ff95b0e 0x55a71ff2877a 0x55a71ff9ae50 0x55a71ff2869a 0x55a71ff9ae50 0x55a71ff95b0e 0x55a71ff2877a 0x55a71ff96a45 0x55a71ff95b0e 0x55a71ff95813 0x55a72005f592 0x55a72005f90d 0x55a72005f7b6\n","tcmalloc: large alloc 1843200000 bytes == 0x55a79228e000 @  0x7f0b8b2091e7 0x7f0b88aed631 0x7f0b88b54680 0x7f0b88be21a7 0x55a71ff27050 0x55a72001899d 0x55a71ff9afe9 0x55a71ff2869a 0x55a71ff9ae50 0x55a71ff95b0e 0x55a71ff2877a 0x55a71ff96a45 0x55a71ff95b0e 0x55a71ff95813 0x55a72005f592 0x55a72005f90d 0x55a72005f7b6 0x55a720037103 0x55a720036dac 0x7f0b89ff3bf7 0x55a720036c8a\n","2021-04-01 06:30:30,620 - INFO - util -   num is 600000\n","tcmalloc: large alloc 1843200000 bytes == 0x55a72449a000 @  0x7f0b8b2091e7 0x7f0b88aed631 0x7f0b88b51ed8 0x7f0b88b51ff3 0x7f0b88c0520d 0x7f0b88c05b6e 0x7f0b88c084e8 0x7f0b88d484d6 0x7f0b88d49fa4 0x7f0b88d4c6f2 0x7f0b88d4d56e 0x55a71ff282c0 0x55a71ff27e99 0x7f0b88c107ab 0x55a720010bc2 0x55a71ff97760 0x55a71ff95b0e 0x55a71ff2877a 0x55a71ff9786a 0x55a71ff95b0e 0x55a71fe67e2b 0x55a71ff981e6 0x55a71ff95b0e 0x55a71fe67e2b 0x7f0b88b3d75d 0x55a71ff26fd7 0x55a71ff26de0 0x55a71ff9aac2 0x55a71ff95b0e 0x55a71ff2877a 0x55a71ff9786a\n","tcmalloc: large alloc 1658880000 bytes == 0x55a8000f2000 @  0x7f0b8b2091e7 0x7f0b88aed631 0x7f0b88b51ed8 0x7f0b88b51ff3 0x7f0b88bdd0f6 0x7f0b88bdd558 0x55a72000ee59 0x55a71ff96fad 0x55a71ff95b0e 0x55a71ff2877a 0x55a71ff96a45 0x55a71ff95b0e 0x55a71ff95813 0x55a72005f592 0x55a72005f90d 0x55a72005f7b6 0x55a720037103 0x55a720036dac 0x7f0b89ff3bf7 0x55a720036c8a\n","2021-04-01 06:30:33,185 - INFO - root -   *************kfid:0\n","2021-04-01 06:30:33,187 - INFO - mautil.pt.models -   start fit\n","2021-04-01 06:30:34,423 - INFO - mautil.pt.models -   ema model created\n","2021-04-01 06:30:37,135 - INFO - mautil.pt.models -   created model on device:cuda\n","2021-04-01 06:30:37,137 - INFO - mautil.pt.models -   \n","\n","Train Epoch:0, lr:0.00000000, loss::   0% 0/1054 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","Train Epoch:0, lr:0.00000819, loss:loss:5.64953987, nmse_loss:5.64953987: 100% 1054/1054 [13:12<00:00,  1.33it/s]\n","Val Epoch:0, loss:: 100% 118/118 [00:32<00:00,  3.62it/s]\n","2021-04-01 06:44:21,943 - INFO - mautil.pt.models -   loss for epoch 0:, train: 5.5182288925833225, val: 5.091916924816067\n","2021-04-01 06:44:22,161 - INFO - mautil.pt.models -   Model saved to file encoder:../data/CSIPlus_p4geenc128ff2104q4e7d7h16d544_kf0b512abs1w1000lr1e4dp0ema999tqbest_KF0/encoder.pth.tar-0, decoder:../data/CSIPlus_p4geenc128ff2104q4e7d7h16d544_kf0b512abs1w1000lr1e4dp0ema999tqbest_KF0/decoder.pth.tar-0\n","2021-04-01 06:44:22,162 - INFO - mautil.pt.models -   best val loss:5.091916924816067, best epoch:0\n","2021-04-01 06:44:22,162 - INFO - mautil.pt.models -   \n","\n","Train Epoch:1, lr:0.00000843, loss::   1% 12/1054 [00:09<13:28,  1.29it/s]\n","Traceback (most recent call last):\n","  File \"train.py\", line 137, in <module>\n","    gl[args.method_name](args)\n","  File \"train.py\", line 63, in kf\n","    model.fit(train_ds, val_ds)\n","  File \"/usr/local/lib/python3.7/dist-packages/mautil/pt/models.py\", line 92, in wrapper\n","    return self.f(**kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/mautil/pt/models.py\", line 713, in fit\n","    step, losses = self.fit_epoch(train_ds, epoch, step, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/mautil/pt/models.py\", line 530, in fit_epoch\n","    grads, losses = self.fit_batch(batch, step)\n","  File \"/content/icompete_csi/csi/models.py\", line 86, in fit_batch\n","    return super().fit_batch(batch, step, phase, model, opt, lr_scheduler)\n","  File \"/usr/local/lib/python3.7/dist-packages/mautil/pt/models.py\", line 416, in fit_batch\n","    outputs = model(**batch)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/icompete_csi/csi/nn.py\", line 1164, in forward\n","    dec = self.decoder(enc, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/icompete_csi/csi/nn.py\", line 1096, in forward\n","    dec = self.decode(enc, return_hidden=return_hidden, **kwargs)\n","  File \"/content/icompete_csi/csi/nn.py\", line 1070, in decode\n","    dec = self.decoder(torch.transpose(inputs, 0, 1), return_hidden=return_hidden)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/icompete_csi/csi/nn.py\", line 736, in forward\n","    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/transformer.py\", line 294, in forward\n","    key_padding_mask=src_key_padding_mask)[0]\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py\", line 985, in forward\n","    attn_mask=attn_mask)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 4144, in multi_head_attention_forward\n","    if torch.equal(query, key) and torch.equal(key, value):\n","KeyboardInterrupt\n","-rw-r--r-- 1 root root 37K Apr  1 06:44 ../data/CSIPlus_p4geenc128ff2104q4e7d7h16d544_kf0b512abs1w1000lr1e4dp0ema999tqbest_KF0/cfg.json\n","-rw-r--r-- 1 root root 50M Apr  1 06:44 ../data/CSIPlus_p4geenc128ff2104q4e7d7h16d544_kf0b512abs1w1000lr1e4dp0ema999tqbest_KF0/encoder.pth.tar-0\n","-rw-r--r-- 1 root root 50M Apr  1 06:44 ../data/CSIPlus_p4geenc128ff2104q4e7d7h16d544_kf0b512abs1w1000lr1e4dp0ema999tqbest_KF0/decoder.pth.tar-0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"L2gM9gU4EERQ"},"source":["# fintuning"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p2OSFRJQEEo9","outputId":"bdfadf8a-c6f7-40f2-b8eb-7aa84f45ac6d"},"source":["os.chdir(os.path.join(WORKDIR, PROJECT))\n","\n","BATCHSIZE = 512\n","KFID = 0\n","KN = 10\n","ENCDIM = 128\n","PQBIT=4\n","QBIT=3\n","WS=1000\n","LDS=100000\n","LR=3e-5\n","ELAYER=7\n","DLAYER=7\n","NHEAD=16\n","DEMODEL=544\n","DDMODEL=544\n","EFFD=2104\n","DFFD=2104\n","\n","\n","MINLOSS=0.085\n","MODELNAME=\"CSIPlus_p4geenc128ff2104q3e7d7h16d544_kf0b512abs1w1000lr1e4dp0ema999tqbest\"\n","!mkdir -p ../data/{MODELNAME}_KF{KFID}\n","!cp ../data/CSIPlus_p{PQBIT}geenc{ENCDIM}ff{EFFD}q4e{ELAYER}d{DLAYER}h{NHEAD}d{DEMODEL}_kf0b512abs1w1000lr1e4dp0ema999tqbest_KF{KFID}/cfg.json ../data/{MODELNAME}_KF{KFID}/\n","\n","!python train.py -m kf  -kfid {KFID} -kn {KN} -ms {MODELNAME} -num {NUM}  -save  -save_best $USE_TPU   -n_es_epoch 20 -n_lr_warmup_step {WS} -n_init_epoch 0 -bs {BATCHSIZE}  -abs 1 -ema 0.9995   -xla_procs 1  -train_quantize  \\\n","-lr {LR}  -n_lr_decay_step {LDS} -lr_decay_rate 0.2  -dp 0 -enc_dim {ENCDIM} -n_q_bit {QBIT} -d_eff {EFFD} -d_dff {DFFD} -n_e_layer {ELAYER} -n_d_layer {DLAYER} -n_ehead {NHEAD}  -n_dhead {NHEAD} -d_emodel {DEMODEL}  -d_dmodel {DDMODEL} \\\n","-activation gelu  -save_half -use_fp16  -es 1e-5 -min_loss {MINLOSS}  -epochs 113 -restore  # -n_epoch_step 10 \n","!ls -ltrh ../data/{MODELNAME}_KF{KFID}/*\n","!cp -r {DATADIR}/{MODELNAME}* \"{WORKDIR}/drive/My Drive/dl/{PROJECT}/data\" && date"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tcmalloc: large alloc 1843208192 bytes == 0x5645895dc000 @  0x7f0b122cf1e7 0x564583f7ef48 0x564583f499c7 0x7f0a4f9d5b32 0x7f0a4fbf0973 0x7f0a4fbf50bd 0x7f0a4fbf88ee 0x7f0a4fc005c0 0x7f0a4fbf25f5 0x564583f4d050 0x56458403e99d 0x564583fc0fe9 0x564583fbbb0e 0x564583f4e77a 0x564583fbcc9e 0x564583fbbb0e 0x564583f4e77a 0x564583fbcc9e 0x564583fbbb0e 0x564583f4e77a 0x564583fc0e50 0x564583f4e69a 0x564583fc0e50 0x564583fbbb0e 0x564583f4e77a 0x564583fbca45 0x564583fbbb0e 0x564583fbb813 0x564584085592 0x56458408590d 0x5645840857b6\n","tcmalloc: large alloc 1843200000 bytes == 0x5645f73d0000 @  0x7f0b122cf1e7 0x7f0b0fbb3631 0x7f0b0fc1a680 0x7f0b0fca81a7 0x564583f4d050 0x56458403e99d 0x564583fc0fe9 0x564583f4e69a 0x564583fc0e50 0x564583fbbb0e 0x564583f4e77a 0x564583fbca45 0x564583fbbb0e 0x564583fbb813 0x564584085592 0x56458408590d 0x5645840857b6 0x56458405d103 0x56458405cdac 0x7f0b110b9bf7 0x56458405cc8a\n","2021-04-01 06:44:44,308 - INFO - util -   num is 600000\n","tcmalloc: large alloc 1843200000 bytes == 0x5645895dc000 @  0x7f0b122cf1e7 0x7f0b0fbb3631 0x7f0b0fc17ed8 0x7f0b0fc17ff3 0x7f0b0fccb20d 0x7f0b0fccbb6e 0x7f0b0fcce4e8 0x7f0b0fe0e4d6 0x7f0b0fe0ffa4 0x7f0b0fe126f2 0x7f0b0fe1356e 0x564583f4e2c0 0x564583f4de99 0x7f0b0fcd67ab 0x564584036bc2 0x564583fbd760 0x564583fbbb0e 0x564583f4e77a 0x564583fbd86a 0x564583fbbb0e 0x564583e8de2b 0x564583fbe1e6 0x564583fbbb0e 0x564583e8de2b 0x7f0b0fc0375d 0x564583f4cfd7 0x564583f4cde0 0x564583fc0ac2 0x564583fbbb0e 0x564583f4e77a 0x564583fbd86a\n","tcmalloc: large alloc 1658880000 bytes == 0x564665234000 @  0x7f0b122cf1e7 0x7f0b0fbb3631 0x7f0b0fc17ed8 0x7f0b0fc17ff3 0x7f0b0fca30f6 0x7f0b0fca3558 0x564584034e59 0x564583fbcfad 0x564583fbbb0e 0x564583f4e77a 0x564583fbca45 0x564583fbbb0e 0x564583fbb813 0x564584085592 0x56458408590d 0x5645840857b6 0x56458405d103 0x56458405cdac 0x7f0b110b9bf7 0x56458405cc8a\n","2021-04-01 06:44:46,659 - INFO - root -   *************kfid:0\n","2021-04-01 06:44:46,665 - INFO - mautil.pt.models -   start fit\n","2021-04-01 06:44:47,888 - INFO - mautil.pt.models -   ema model created\n","2021-04-01 06:44:50,687 - INFO - mautil.pt.models -   created model on device:cuda\n","2021-04-01 06:44:50,898 - INFO - mautil.pt.models -   model restored from ../data/CSIPlus_p4geenc128ff2104q4e7d7h16d544_kf0b512abs1w1000lr1e4dp0ema999tqbest_KF0/encoder.pth.tar-0, ../data/CSIPlus_p4geenc128ff2104q4e7d7h16d544_kf0b512abs1w1000lr1e4dp0ema999tqbest_KF0/decoder.pth.tar-0\n","2021-04-01 06:44:50,903 - INFO - mautil.pt.models -   \n","\n","Train Epoch:1, lr:0.00000000, loss::   0% 0/1054 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","Train Epoch:1, lr:0.00000768, loss:loss:1.70155264, nmse_loss:1.70155264:  28% 293/1054 [03:40<09:32,  1.33it/s]"],"name":"stdout"}]}]}